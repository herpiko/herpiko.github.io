<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Blog</title>
    <link>//localhost:1313/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 May 2020 00:00:00 +0700</lastBuildDate>
    <atom:link href="//localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tensorflow GPU on Nvidia 1660 Ti</title>
      <link>//localhost:1313/post/2020/05/05/tensorflow-gpu-on-nvidia-1660-ti/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0700</pubDate>
      <guid>//localhost:1313/post/2020/05/05/tensorflow-gpu-on-nvidia-1660-ti/</guid>
      <description>&lt;img src=&#34;//localhost:1313/images/2020-05-05-1660ti.jpg&#34;/&gt;&#xA;&lt;p&gt;Although my GPU &lt;a href=&#34;https://developer.nvidia.com/cuda-gpus#compute&#34;&gt;is not listed here&lt;/a&gt;, I can confirm that 1660 Ti works. The machine learning training is now significantly faster than using CPU.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;➜  imagerec git:&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;updated-deps&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; ✗ nvidia-smi&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Tue May  &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; 15:00:40 &lt;span style=&#34;color:#ae81ff&#34;&gt;2020&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+-----------------------------------------------------------------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|-------------------------------+----------------------+----------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;===============================&lt;/span&gt;+&lt;span style=&#34;color:#f92672&#34;&gt;======================&lt;/span&gt;+&lt;span style=&#34;color:#f92672&#34;&gt;======================&lt;/span&gt;|&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;  GeForce GTX 166...  On   | 00000000:01:00.0  On |                  N/A |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| 32%   35C    P8    12W / 130W |    293MiB /  5941MiB |      2%      Default |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+-------------------------------+----------------------+----------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+-----------------------------------------------------------------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;| Processes:                                                       GPU Memory |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|  GPU       PID   Type   Process name                             Usage      |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|&lt;span style=&#34;color:#f92672&#34;&gt;=============================================================================&lt;/span&gt;|&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;      &lt;span style=&#34;color:#ae81ff&#34;&gt;1549&lt;/span&gt;      G   /usr/lib/xorg/Xorg                            18MiB |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;      &lt;span style=&#34;color:#ae81ff&#34;&gt;1953&lt;/span&gt;      G   /usr/bin/gnome-shell                          48MiB |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;      &lt;span style=&#34;color:#ae81ff&#34;&gt;2592&lt;/span&gt;      G   /usr/lib/xorg/Xorg                           108MiB |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;|    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;      &lt;span style=&#34;color:#ae81ff&#34;&gt;2725&lt;/span&gt;      G   /usr/bin/gnome-shell                         114MiB |&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;+-----------------------------------------------------------------------------+&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;➜  imagerec git:&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;updated-deps&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; ✗ python&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Python 3.7.7 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default, May  &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; 2020, 04:20:38&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;GCC 7.5.0&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; on linux&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;help&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;copyright&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;credits&amp;#34;&lt;/span&gt; or &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;license&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; more information.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; from tensorflow.python.client import device_lib&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:16.900600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libnvinfer.so.6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:16.901543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libnvinfer_plugin.so.6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; device_lib.list_local_devices&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.071110: I tensorflow/core/platform/cpu_feature_guard.cc:142&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.100259: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; CPU Frequency: &lt;span style=&#34;color:#ae81ff&#34;&gt;3692985000&lt;/span&gt; Hz&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.100906: I tensorflow/compiler/xla/service/service.cc:168&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; XLA service 0x55d1bb829330 initialized &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; platform Host &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;this does not guarantee that XLA will be used&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;. Devices:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.100968: I tensorflow/compiler/xla/service/service.cc:176&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;   StreamExecutor device &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: Host, Default Version&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.105053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcuda.so.1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.217053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.217492: I tensorflow/compiler/xla/service/service.cc:168&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; XLA service 0x55d1bb8b7590 initialized &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; platform CUDA &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;this does not guarantee that XLA will be used&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;. Devices:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.217525: I tensorflow/compiler/xla/service/service.cc:176&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;   StreamExecutor device &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: GeForce GTX &lt;span style=&#34;color:#ae81ff&#34;&gt;1660&lt;/span&gt; Ti, Compute Capability 7.5&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.217760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.218479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Found device &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; with properties:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pciBusID: 0000:01:00.0 name: GeForce GTX &lt;span style=&#34;color:#ae81ff&#34;&gt;1660&lt;/span&gt; Ti computeCapability: 7.5&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;coreClock: 1.86GHz coreCount: &lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt; deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.218590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcudart.so.10.1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.218654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcublas.so.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.220646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcufft.so.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.221035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcurand.so.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.223176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcusolver.so.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.224561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcusparse.so.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.224651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcudnn.so.7&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.224857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.225935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.226839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Adding visible gpu devices: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.226907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Successfully opened dynamic library libcudart.so.10.1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.443386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Device interconnect StreamExecutor with strength &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; edge matrix:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.443435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;      &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.443446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 0:   N&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.443650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.444083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; successful NUMA node read from SysFS had negative value &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, but there must be at least one NUMA node, so returning NUMA node zero&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2020-05-05 15:01:21.444563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Created TensorFlow device &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;/device:GPU:0 with &lt;span style=&#34;color:#ae81ff&#34;&gt;5176&lt;/span&gt; MB memory&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; -&amp;gt; physical GPU &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;device: 0, name: GeForce GTX &lt;span style=&#34;color:#ae81ff&#34;&gt;1660&lt;/span&gt; Ti, pci bus id: 0000:01:00.0, compute capability: 7.5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;name: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/device:CPU:0&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;device_type: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CPU&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;memory_limit: &lt;span style=&#34;color:#ae81ff&#34;&gt;268435456&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;locality &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;incarnation: &lt;span style=&#34;color:#ae81ff&#34;&gt;7827239615455337760&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;, name: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/device:XLA_CPU:0&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;device_type: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;XLA_CPU&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;memory_limit: &lt;span style=&#34;color:#ae81ff&#34;&gt;17179869184&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;locality &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;incarnation: &lt;span style=&#34;color:#ae81ff&#34;&gt;9475332420332566901&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;physical_device_desc: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;device: XLA_CPU device&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;, name: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/device:XLA_GPU:0&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;device_type: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;XLA_GPU&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;memory_limit: &lt;span style=&#34;color:#ae81ff&#34;&gt;17179869184&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;locality &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;incarnation: &lt;span style=&#34;color:#ae81ff&#34;&gt;11551463581523616297&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;physical_device_desc: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;device: XLA_GPU device&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;, name: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/device:GPU:0&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;device_type: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GPU&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;memory_limit: &lt;span style=&#34;color:#ae81ff&#34;&gt;5427691520&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;locality &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  bus_id: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  links &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;incarnation: &lt;span style=&#34;color:#ae81ff&#34;&gt;634448236828243524&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;physical_device_desc: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using CPU,&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
